import requests
import pickle
from  openai import OpenAI
from pathlib import Path
from django.conf import settings
import uuid
from sklearn.metrics.pairwise import cosine_similarity

emb_API_KEY = 'up_VFfKpHPe17rAGRAKk40AwxtnzWOMb'
CACHE_PATH = Path("book_vectors.pkl")
BATCH_SIZE = 100 

def generate_image_with_openai(thread_title, thread_content, book_title, book_author):

    keyword_extractor_prompt = (
        f"""
        {book_author}ì˜ ì±… {book_title}ì„ ì½ê³  ì“´ ë…ì„œ ë‹¤ì´ì–´ë¦¬ì˜ ê°ì •ì„ ë¶„ì„í•´ í‚¤ì›Œë“œ 5ê°œë¥¼ ì¶”ì¶œí•˜ì‹œì˜¤.
        í‚¤ì›Œë“œ ì¶”ì¶œì´ ì™„ë£Œëë‹¤ë©´ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„± AIì— ì œê³µí•  í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì‹œì˜¤.
        í•´ë‹¹ í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ í•´ë‹¹ ë…ì„œ ë‹¤ì´ì–´ë¦¬ í˜ì´ì§€ì˜ ì¸ë„¤ì¼ ì´ë¯¸ì§€ë¥¼ ìƒì„± ì˜ˆì •.
        ìƒì„±í•  ìµœì¢… ì´ë¯¸ì§€ëŠ” ì¶”ìƒì ì´ê³  ëª¨í˜¸í•œ í˜•íƒœì˜ ì´ˆí˜„ì‹¤ì£¼ì˜ì ì¸ ê·¸ë¦¼ì´ì–´ì•¼ í•¨. 

        <ë…ì„œ ë‹¤ì´ì–´ë¦¬>
            <ì œëª©>{thread_title}</ì œëª©>
            <ë³¸ë¬¸>{thread_content}</ë³¸ë¬¸>
        </ë…ì„œ ë‹¤ì´ì–´ë¦¬>

        <ë‹µë³€ ì˜ˆì‹œ>
            ë¶ˆì•ˆ, ê²©ì •, ì°¬ë€í•¨, ë…¸ìŠ¤í…”ì§€ì•„, í¬ë§ì´ ë‹´ê¸´ Abstract expressionism ìŠ¤íƒ€ì¼ì˜ ì¶”ìƒí™”
        </ë‹µë³€ ì˜ˆì‹œ>

        ë‹µë³€ : 
        """
    )
    client = OpenAI(api_key="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")
    keyword_extractor_response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ìƒì„± AIë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„± ë¹„ì„œì…ë‹ˆë‹¤."},
            {"role": "user", "content": keyword_extractor_prompt},
        ],
        max_tokens=2040,
        temperature=0.5
    )
    keyword_extractor_response = keyword_extractor_response.choices[0].message.content
    
    img_generator_prompt = keyword_extractor_response + " ì–´ë– í•œ í…ìŠ¤íŠ¸, ê¸€ì, ìˆ«ì, ì‹¬ë³¼ë„ í¬í•¨í•˜ì§€ ì•Šì„ ê²ƒ"
    print(img_generator_prompt)

    response = client.images.generate(
        model="dall-e-3",
        prompt=img_generator_prompt,
        size="1792x1024",
        quality="standard",
        n=1,
    )

    image_url = response.data[0].url
    
    response_img = requests.get(image_url)
    if response_img.status_code == 200:
        output_dir = Path(settings.MEDIA_ROOT) / "thread_cover_img"
        output_dir.mkdir(parents=True, exist_ok=True)
        file_name = f"{uuid.uuid4()}.png"
        file_path = output_dir / file_name
        file_path.write_bytes(response_img.content)
        return str(Path("thread_cover_img") / file_name)

    return None

def embed_books(book_desc_list):
    headers = {
        "Authorization": f"Bearer {emb_API_KEY}",
        "Content-Type": "application/json",
    }
    data = {
        "input": book_desc_list,
        "model": "solar-embedding-1-large-passage",
    }
    response = requests.post(
        "https://api.upstage.ai/v1/solar/embeddings",
        headers=headers,
        json=data,
    )
    response.raise_for_status()
    return [item["embedding"] for item in response.json()["data"]]

def get_or_create_book_vectors(books):
    if CACHE_PATH.exists():
        with open(CACHE_PATH, "rb") as f:
            return pickle.load(f)

    # ì „ì²´ ì±… ì„¤ëª… í•„í„°ë§
    descs = [
        b.description.strip()[:2048]
        for b in books
        if b.description and isinstance(b.description, str) and b.description.strip()
    ]

    # ì—¬ëŸ¬ ë°°ì¹˜ë¡œ ë‚˜ëˆ ì„œ ë²¡í„° ìƒì„±
    all_vectors = []
    for i in range(0, len(descs), BATCH_SIZE):
        batch = descs[i:i+BATCH_SIZE]
        print(f"ğŸ”„ Embedding batch {i} ~ {i+len(batch)-1}")
        vectors = embed_books(batch)
        all_vectors.extend(vectors)

    # ê²°ê³¼ ìºì‹œ ì €ì¥
    with open(CACHE_PATH, "wb") as f:
        pickle.dump(all_vectors, f)

    return all_vectors

def recommend_similar_books(target_index, all_embeddings, top_k=6):
    sims = cosine_similarity([all_embeddings[target_index]], all_embeddings)[0]
    sim_scores = list(enumerate(sims))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    return [idx for idx, _ in sim_scores[1:top_k+1]]